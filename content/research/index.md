+++ 
title = "Research" 
menu = "main"
+++

Previously, I was an Artificial Intelligence research assistant at the University of Missouri (MIZ-ZOU!) working with [Derek Anderson](https://derektanderson.com/) and the [Center for Geospatial Intelligence](https://engineering.missouri.edu/research/featured/center-for-geospatial-intelligence-cgi/). Our work focused on eXplainable AI (XAI), specifically developing new neuro-fuzzy systems that explain their own decision-making steps.

**What did I research?**
I went to grad school to research the AI Alignment problem, which is similar to AI safety, AI risk research, etc. Alignment is more specific than safety because it doesn't just mean trustworthy and harmless, it also means beneficial. We want to create AI that is *aligned* with our goals of creating a better world. 

**How do we create aligned AIs?** Great question, it's really hard. There are many techniques that attempt to align AI actions with human desires, and there are a myriad of problems that come along with every technique. eXplainable AI (XAI) is one broad set of techniques used to develop AIs that explain their mathematical reasoning using more math. Remember, all AIs are just computer algorithms that perform a series of computations on inputs (a vector of scalars) to generate outputs (a vector of scalars). Neural Networks (NNs) are the dominant algorithm in AI right now, and they are composed of many layers of math that get really confusing because of the depth and breadth of the layers, which means the sheer number of computations can be mind-boggling for one person to try to understand. Any technique to explain what a NN is doing could be helpful. 

**What did we do?** We approached this problem by adding an additional layer of fuzzy math at the end of the NN that attempts to explain some of the reasoning (if you can call it that) steps used by the AI. These new techniques do not explain every step along the NN, but mainly the final decision-making step. Eventually, this research direction may attempt to add more layers of math to explain the NNs, but we showed state-of-the-art improvements in explainability and human-in-the-loop interaction to create more trustworthy, and better-performing AI algorithms.

**What degree did you get?** I received a Master of Science in Computer Science. I did a research-based Masters, which is different from a class-based Masters. Class-based Masters take 60 credit hours of continuing education, the point is to take more classes. Research-based Masters take 30 credit hours of education and perform 30 hours of thesis research, submit a final thesis, and defend it with an hour-long oral presentation. The point of this Masters is training to become a scientist (basically half of a PhD), which is why I did so much research.

Here, I've listed the references to my published work. If you have any questions, feel free to reach out (contact info on [my home page](/)).

---

## M.S. Thesis
- **B. Ruprecht**. "EXPLAINABLE PARTS-BASED CONCEPT MODELING AND REASONING". University of Missouri, 2023. [PDF](ruprecht_ms_thesis.pdf)

## Journal Articles
- A. Cannaday, C. Davis, G. Scott, **B. Ruprecht**, and D. T. Anderson, "Broad Area Search and Detection of Surface-to-Air Missile Sites Using Spatial Fusion of Component Object Detections from Deep Neural Networks", IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2020. [PDF](cannaday_aeors2020.pdf)

## Conference Articles
- B. Young, D. T. Anderson, J. Keller, F. Petry, C. Michael and **B. Ruprecht**, "Human-Oriented Fuzzy Set Based Explanations of  Spatial Concepts," WCCI 2023. [PDF](young_wcci2023.pdf)

- **B. Ruprecht**, D. T. Anderson, F. Petry, J. M. Keller, C. Michael, A. Buck, G. Scott, C. Davis, "Concept Learning Based on Human Interaction and Explainable AI," SPIE 2021. [PDF](ruprecht_spie2021.pdf)

- **B. Ruprecht**, W. Wu, M. Islam, D. T. Anderson, J. Keller, G. Scott, C. Davis, F. Petry, P. Elmore, K. Nock, E. Gilmour, “Possibilistic Clustering Enabled Neuro Fuzzy Logic,” WCCI 2020. [PDF](ruprecht_wcci2020.pdf). [code](https://github.com/blakeruprecht/ANFIS-SP1M).

- **B. Ruprecht**, C. Veal, A. Cannaday, D. T. Anderson, F. Petry, J. Keller, G. Scott, C. Davis, C. Norsworthy, P. Elmore, K. Nock, E. Gilmour, “Neuro-fuzzy logic for parts-based reasoning about complex scenes in remotely sensed data”, SPIE 2020. [PDF](ruprecht_spie2020.pdf). [code](https://github.com/blakeruprecht/Fuzzy-Fusion).

## Poster Presentations
- **B. Ruprecht**, C. Veal, B. Murray, M.A. Islam, D.T. Anderson, F. Petry, J. Keller, G. Scott, and C. Davis, "Fuzzy Logic-Based Fusion of Deep Learners in Remote Sensing," FuzzIEEE 2019.
