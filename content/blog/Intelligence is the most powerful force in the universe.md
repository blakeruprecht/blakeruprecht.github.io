---
title: {{title}}
date: {{date}}
draft: false
---

Really, intelligence is the tool we use to win the game. Since [[Reward drives behavior]], we seek out rewards. And rewards are just another type of winning, and we know that [[Winning requires ability, practice, and love]]. 

Naval Ravikant said "the truest sign of intelligence is getting what you want out of life." In reinforcement learning, we formulate all problems as having a goal state (the thing you want), and teach robots to learn how to get there. This problem is extremely difficult, since there are infinitely many (well, not really, constrained by human capability) paths to go from current-state to goal-state. Reward learning is based on the idea that rewards are something the agent wants, and will act accordingly to figure out how to get that reward. Intelligence is so powerful that we as ape creatures with no fangs or strong muscles (compared to elephants, gorillas, and tigers) can dominate the earth and go to the moon.

---
## References
- Naval Ravikant: "the truest sign of intelligence is getting what you want out of life"
- Eliezer Yudkowsky: "I keep trying to explain to people that the archetype of intelligence is not Dustin Hoffman in 'The Rain Man;' it is a human being, period. It is squishy things that explode in a vacuum, leaving footprints on their moon."