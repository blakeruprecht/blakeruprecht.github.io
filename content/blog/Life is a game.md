---
date: 2023-09-14
---


I studied this topic in graduate school, and it continues to fascinate me. I heard this quote one time, "Intelligence is the ability to get what you want." From an artificial intelligence (AI) persepective, I believe this to be true, but is it true from a human perspective?

To begin, I studied the creation of intelligent agents. The simplest example is giving a computer "brain" the controls to a video game character, and telling the computer to win the game. Reinforcement Learning (RL) is a branch of AI that studies techniques to teach computer brains (typically a neural network) how to accomplish tasks in game environments. For example, RL agents have successfully learned how to defeat human masters at Chess and Go, as well as large, complex video games like DOTA 2. Modern RL agents can play Minecraft successfully. I'm not going to go into the details of how they do this, but basically, the agents choose a goal, like winning, getting more points than the competition, etc., and then perform random actions until they get a reward. This reward "reinforces" (hence the name) their previous behavior. Once they achieve a reward, the agent has to decide how to balance exploring new random actions, and exploiting the actions it already knows will lead to a reward. In theory it sounds pretty easy, but actually coding it up is a bit of a cl\*sterfuck. 

This is one of the most exciting and promising areas of AI research currently, and I find it fascinating that AI agents are basically one step away from becoming sentient -- once they can figure out how to choose their own goals and optimize for those, what's the difference between an RL AI agent and a dog? Do we as humans even choose our own goals, or are they baked into us from our DNA (existing goal code passed down from our parents) and our environments (goals taught to us by teachers). Both of these steps are entirely plausible to code into an AI. While it's not trivial, I think it's doable to code goals into an AI agent, let the AI agents procreate and mutate those goals, and then whichever agents survive better in any given game/environment end up passing down their successful codes. For example, imagine a Minecraft multiplayer server full of AI agents. They can each have certain goals, for example "build a large farm to create a lot of food", or "murder other players", or "defeat the most creepers in battle", along with the basic goal of "stay alive/don't die" (I guess there are probably going to be some lemmings as well). Which multiplayer AI agents would do best in this scenario? If there were hundreds on the same server, and those agents had the opportunity to breed, where after 50 days or so they paired up, created an offspring that was the combination between the two parents, and then the parents survived another 20 days then died. After a while, you might see random goals pop-up that were not in the original genetic code due to mutation. I dunno, but this idea isn't far-fetched.

I don't think it's a stretch to call life a game. Sure, it's a weird paradigm for some, but as a gamer since I was a kid, the analogy feels natural. There are rules to the game (mainly physics, but I tend to also follow social/local/state/national rules as well), goals (who doesn't want a sexy partner or tons of friends?), and actions we can take to accomplish these goals (already discussed previously, I exploit exercise frequently, without accomplishing some of the main exercise goals others have (and me too, at times)). But what I like most about calling it a game is the freedom that definition provides. Sure, there are challenges to life, and plenty of griefers who set out to ruin it for others, but if you can avoid those people, you're free to play the game as you see fit. The whole point of being an intelligent agent, with actual agency, is that **you** get to choose what goals you have. Nobody else can tell you what path you should be on, on what you should strive to accomplish, or what actions to take to get there. To often, I hear complaints from people that unintentionally strip themselves of agency. Oh, I *have* to do this because my parent/partner/friend/government/boss/overlord told me to. No you fucking don't, every single time, you do it because you make the choice to. It's freeing, but it also puts the responsibility completely on your own shoulders. And this is how it should be.

If there was some magical sky-being that told you how to live, and threatened you with eternal damnation if you didn't listen, would you pay attention? I sure as hell would, but good thing there isn't one of those! If the government based their laws on the best current understanding of the human condition, rather than the outdated values of some old rich fuckers from a different time period, would you listent to that government? I still probably wouldn't, because that understanding needs to flexible to accomadate new data and research, and in my experience, government is anything but flexible. Would you listen to your peers, who are probably as intelligent as you, but have different genetic goals and lived experiences leading them to value different things in life than you? Maybe. But they're still mortal, fallible, and blinded by things in their own life, just as you are in yours. Your brain is far from the all-seeing, all-knowing computer that our ego tries to convince you it is. Hell, if you believe anything in life with absolute certainty and conviction, you're most likely wrong in some case or context. I'm not saying you *definitely* are, because I am not omnipotent either. Isn't that just the funny thing about life, we were gifted these powerful computers in our skulls that are good enough to give us conviction, but not good enough to prove it. If you believe in a sky-god, or in bacteria, it doesn't matter. It's your game, are you winning?