<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Researches on Blake Ruprecht</title>
    <link>https://blakeruprecht.github.io/research/</link>
    <description>Recent content in Researches on Blake Ruprecht</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://blakeruprecht.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Research</title>
      <link>https://blakeruprecht.github.io/research/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blakeruprecht.github.io/research/research/</guid>
      <description>Previously, I was an Artificial Intelligence researcher at the University of Missouri (MIZ-ZOU!) working with Derek Anderson and the Center for Geospatial Intelligence. Our work focused on eXplainable AI (XAI), specifically developing new neuro-fuzzy systems.
I was trying to make headway on the AI Alignment problem, which basically means make an AI that is safe and trustworthy. XAI is one broad set of techniques to develop AI systems that explain their reasoning using formal methods.</description>
    </item>
    
  </channel>
</rss>
